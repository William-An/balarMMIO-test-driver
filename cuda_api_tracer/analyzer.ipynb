{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SST Balar analyzer script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common import *\n",
    "import logging\n",
    "from yaml import load, dump\n",
    "from optparse import OptionParser\n",
    "import yaml\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load app configuration var\n",
    "benchmark_suites_list = [\"GPU_Microbenchmark\", \"rodinia_2.0-ft\"]\n",
    "benchmark_suites_table = yaml.load(open(\"../define-all-apps.yml\"), Loader=Loader)\n",
    "trace_folder = \"./hw_traces\"\n",
    "root_logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stats files\n",
    "mmio_stats_file = \"mmio_stats.json\"\n",
    "original_stats_file = \"original_stats.json\"\n",
    "mmio_stats = json.load(open(mmio_stats_file))\n",
    "original_stats = json.load(open(original_stats_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get the correct bytes ratio for all benchmarks\n",
    "\"\"\"\n",
    "avg_ratios = []\n",
    "for app_record in get_benchmark_app(benchmark_suites_list, trace_folder, benchmark_suites_table, root_logger):\n",
    "    benchmark_suite_name = app_record[\"benchmark_suite_name\"]\n",
    "    app_name = app_record[\"app_name\"]\n",
    "    app_args_name = get_argfoldername(app_record[\"app_args\"])\n",
    "\n",
    "    try:\n",
    "        app_specific_stat = mmio_stats[benchmark_suite_name][app_name][app_args_name]\n",
    "        sst_stat = app_specific_stat[\"sst\"]\n",
    "        gpgpusim_stat = app_specific_stat[\"gpgpusim\"]\n",
    "        # print(sst_stat.keys())\n",
    "        # print(gpgpusim_stat.keys())\n",
    "        try:\n",
    "            ratio_stat = sst_stat[\"cpu\"][\"correct_memD2H_ratio\"]\n",
    "            ratio_sum = ratio_stat[\"Sum.f64\"]\n",
    "            ratio_max = ratio_stat[\"Max.f64\"]\n",
    "            ratio_min = ratio_stat[\"Min.f64\"]\n",
    "            ratio_count = ratio_stat[\"Count.u64\"]\n",
    "            avg_ratio = ratio_sum / ratio_count\n",
    "            avg_ratios.append(avg_ratio)\n",
    "            print(f\"{app_name}-{app_args_name} correct byte ratio: avg: {avg_ratio} max: {ratio_max} min: {ratio_min}\")\n",
    "        except KeyError:\n",
    "            root_logger.warning(f\"SST TestCPU memcpyD2H ratio stat for app: {app_name} in {benchmark_suite_name} with args: {app_args_name} does not exist!\")\n",
    "    except KeyError:\n",
    "        root_logger.warning(f\"Stats for app: {app_name} in {benchmark_suite_name} with args: {app_args_name} does not exist!\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_dpi(150)\n",
    "ax.set_title(\"Average memcpyH2D correct ratio across all benchmarks: \\n{}\".format(\"-\".join(benchmark_suites_list)))\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Correct bytes ratio\")\n",
    "ax.grid(True)\n",
    "ax.hist(avg_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpgpusim_kernel_stat_keys = [\"count\", \"latency\", \"dram_traffic\", \"smem_bk_conflicts\", \"smem_warp\", \"gmem_access_generated\", \"gmem_warp\", \"exposed_latency\", \"warp_divergence\"]\n",
    "mmio_gpgpusim_kernel_stats = dict.fromkeys(gpgpusim_kernel_stat_keys, [])\n",
    "original_gpgpusim_kernel_stats = dict.fromkeys(gpgpusim_kernel_stat_keys, [])\n",
    "gpgpusim_kernel_annotate = []\n",
    "for app_record in get_benchmark_app(benchmark_suites_list, trace_folder, benchmark_suites_table, root_logger):\n",
    "    benchmark_suite_name = app_record[\"benchmark_suite_name\"]\n",
    "    app_name = app_record[\"app_name\"]\n",
    "    app_args_name = get_argfoldername(app_record[\"app_args\"])\n",
    "\n",
    "    try:\n",
    "        # Get stats for both balar version\n",
    "        mmio_app_specific_stat = mmio_stats[benchmark_suite_name][app_name][app_args_name]\n",
    "        original_app_specific_stat = original_stats[benchmark_suite_name][app_name][app_args_name]\n",
    "        mmio_sst_stat = mmio_app_specific_stat[\"sst\"]\n",
    "        mmio_gpgpusim_stat = mmio_app_specific_stat[\"gpgpusim\"]\n",
    "        original_sst_stat = original_app_specific_stat[\"sst\"]\n",
    "        original_gpgpusim_stat = original_app_specific_stat[\"gpgpusim\"]\n",
    "\n",
    "        # TODO Analyze gpgpusim kernel stat first\n",
    "        for kernel in mmio_gpgpusim_stat:\n",
    "            mmio_kernel_stat = mmio_gpgpusim_stat[kernel]\n",
    "            original_kernel_stat = original_gpgpusim_stat[kernel]\n",
    "            for line in mmio_kernel_stat:\n",
    "                mmio_line_stat = mmio_kernel_stat[line]\n",
    "                original_line_stat = original_kernel_stat[line]\n",
    "                for i in range(len(gpgpusim_kernel_stat_keys)):\n",
    "                    key = gpgpusim_kernel_stat_keys[i]\n",
    "                    mmio_gpgpusim_kernel_stats[key].append(mmio_line_stat[i])\n",
    "                    original_gpgpusim_kernel_stats[key].append(original_line_stat[i])\n",
    "                gpgpusim_kernel_annotate.append(f\"{kernel}-{line}\")\n",
    "    except KeyError as err:\n",
    "        root_logger.warning(f\"Encount error when processing: {app_name} in {benchmark_suite_name} with args: {app_args_name}; msg: {repr(err)}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the kernel stats\n",
    "# mmio_gpgpusim_kernel_stats\n",
    "# original_gpgpusim_kernel_stats\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_dpi(150)\n",
    "ax.set_title(\"GPGPUSim kernel line count across all benchmarks: \\n{}\".format(\"-\".join(benchmark_suites_list)))\n",
    "ax.set_ylabel(\"MMIO\")\n",
    "ax.set_xlabel(\"Original\")\n",
    "ax.grid(True)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "original_arr = original_gpgpusim_kernel_stats[\"count\"]\n",
    "mmio_arr = mmio_gpgpusim_kernel_stats[\"count\"]\n",
    "ax.scatter(original_arr, mmio_arr, c=\"red\")\n",
    "ax.plot(original_arr, original_arr)\n",
    "# for i, text in enumerate(gpgpusim_kernel_annotate):\n",
    "#     ax.annotate(text, (original_arr[i], mmio_arr[i]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd7a13fd55a362c9807f6cfd540a57e69437adaaf6868eabc12ef595ef54c3be"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
